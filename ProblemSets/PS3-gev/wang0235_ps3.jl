# Question 1
using CSV, DataFrames, GLM, LinearAlgebra, Optim, Random, Statistics, HTTP

url = "https://raw.githubusercontent.com/OU-PhD-Econometrics/fall-2024/master/ProblemSets/PS3-gev/nlsw88w.csv"
df = CSV.read(HTTP.get(url).body, DataFrame)

# Convert X to Float64 to avoid type mismatch
X = [df.age df.white df.collgrad]
Z = hcat(df.elnwage1, df.elnwage2, df.elnwage3, df.elnwage4,
         df.elnwage5, df.elnwage6, df.elnwage7, df.elnwage8)
y = df.occupation

function multinomial_logit(X, Z, Î², Î³)
    J = 8 # Number of occupation choices
    N = size(X, 1) # Number of individuals
    
    P = zeros(N, J)
    
    for i in 1:N
        for j in 1:(J-1)
            Z_diff = Z[i, j] - Z[i, J] # Differencing Z's as per the instruction
            numerator = exp(dot(X[i, :], Î²[j, :]) + Î³ * Z_diff)
            denominator = 1 + sum([exp(dot(X[i, :], Î²[k, :]) + Î³ * (Z[i, k] - Z[i, J])) for k in 1:(J-1)])
            P[i, j] = numerator / denominator
        end
        P[i, J] = 1 / (1 + sum([exp(dot(X[i, :], Î²[k, :]) + Î³ * (Z[i, k] - Z[i, J])) for k in 1:(J-1)]))
    end
    
    return P
end


# Initial parameter guesses (random initialization)
Î²_initial = randn(size(X, 2), J-1)
Î³_initial = randn(1)
initial_params = vcat(vec(Î²_initial), Î³_initial)

# Minimize the negative log-likelihood
result = optimize(params -> log_likelihood(params, X, Z, y, J), initial_params, BFGS())

# Extract the estimated parameters
estimated_params = result.minimizer
Î²_hat = reshape(estimated_params[1:end-1], size(X, 2), J-1)
Î³_hat = estimated_params[end]

println("Estimated Î² coefficients: ", Î²_hat)
println("Estimated Î³ coefficient: ", Î³_hat)


# Question 2
# The estimated value of ð›¾ (-0.094) being negative implies that as the value of the alternative-specific variable in ð‘ (such as wage difference) increases, the probability of choosing that occupation decreases. 
# In other words, higher wage differences reduce the likelihood of someone choosing that occupation. This negative relationship indicates that wage differences have a deterrent effect on occupational choice.


# Question 3
using CSV, DataFrames, Optim, LinearAlgebra, HTTP

url = "https://raw.githubusercontent.com/OU-PhD-Econometrics/fall-2024/master/ProblemSets/PS3-gev/nlsw88w.csv"
df = CSV.read(HTTP.get(url).body, DataFrame)

# Define the variables
X = [df.age df.white df.collgrad]
Z = hcat(df.elnwage1, df.elnwage2, df.elnwage3, df.elnwage4,
         df.elnwage5, df.elnwage6, df.elnwage7, df.elnwage8)
y = df.occupation

# Define nests
WC = [1, 2, 3]  # White collar occupations
BC = [4, 5, 6, 7]  # Blue collar occupations
Other = [8]  # Other

# Log-likelihood function for nested logit
function log_likelihood_nested(params, X, Z, y, WC, BC, Other)
    # Extract parameters
    Î²_WC = params[1:3]
    Î²_BC = params[4:6]
    Î³ = params[7]
    Î»_WC = params[8]
    Î»_BC = params[9]
    
    ll = 0.0
    
    for i in 1:size(X, 1)
        # Calculate sums for the white collar and blue collar nests
        sum_WC = sum(exp((dot(X[i, :], Î²_WC) + Î³ * (Z[i, j] - Z[i, 8])) / Î»_WC) for j in WC)
        sum_BC = sum(exp((dot(X[i, :], Î²_BC) + Î³ * (Z[i, j] - Z[i, 8])) / Î»_BC) for j in BC)
        
        # Ensure sum_WC and sum_BC are scalars, and then raise to the power of Î»
        denom = sum_WC^Î»_WC + sum_BC^Î»_BC
        
        # Add likelihood contributions
        if y[i] in WC
            ll += log(exp((dot(X[i, :], Î²_WC) + Î³ * (Z[i, y[i]] - Z[i, 8])) / Î»_WC) / denom)
        elseif y[i] in BC
            ll += log(exp((dot(X[i, :], Î²_BC) + Î³ * (Z[i, y[i]] - Z[i, 8])) / Î»_BC) / denom)
        elseif y[i] in Other
            ll += log(1 / denom)
        end
    end
    
    return -ll  # Return negative log-likelihood
end

# Initial parameter guess (flattened vector)
initial_params = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0]

# Optimize the negative log-likelihood
result = optimize(params -> log_likelihood_nested(params, X, Z, y, WC, BC, Other), initial_params, BFGS())

# Extract the estimated parameters
estimated_params = result.minimizer
Î²_WC_hat = estimated_params[1:3]
Î²_BC_hat = estimated_params[4:6]
Î³_hat = estimated_params[7]
Î»_WC_hat = estimated_params[8]
Î»_BC_hat = estimated_params[9]

println("Estimated Î²_WC: ", Î²_WC_hat)
println("Estimated Î²_BC: ", Î²_BC_hat)
println("Estimated Î³: ", Î³_hat)
println("Estimated Î»_WC: ", Î»_WC_hat)
println("Estimated Î»_BC: ", Î»_BC_hat)


# Question 4
# Wrap function for Q1
using CSV, DataFrames, GLM, LinearAlgebra, Optim, Random, Statistics, HTTP
function estimate_multinomial_logit()
    url = "https://raw.githubusercontent.com/OU-PhD-Econometrics/fall-2024/master/ProblemSets/PS3-gev/nlsw88w.csv"
    df = CSV.read(HTTP.get(url).body, DataFrame)

    # Convert X to Float64 to avoid type mismatch
    X = [df.age df.white df.collgrad]
    Z = hcat(df.elnwage1, df.elnwage2, df.elnwage3, df.elnwage4,
             df.elnwage5, df.elnwage6, df.elnwage7, df.elnwage8)
    y = df.occupation

    function log_likelihood(params, X, Z, y, J)
        Î² = reshape(params[1:end-1], size(X, 2), J-1)
        Î³ = params[end]
        ll = 0.0

        for i in 1:size(X, 1)
            denom = 1 + sum(exp(dot(X[i, :], Î²[:, j]) + Î³ * (Z[i, j] - Z[i, J])) for j in 1:(J-1))
            for j in 1:(J-1)
                if y[i] == j
                    prob = exp(dot(X[i, :], Î²[:, j]) + Î³ * (Z[i, j] - Z[i, J])) / denom
                    ll += log(prob)
                end
            end
            if y[i] == J
                prob = 1 / denom
                ll += log(prob)
            end
        end

        return -ll  # Return negative log-likelihood for minimization
    end

    J = 8
    # Initial parameter guesses (random initialization)
    Î²_initial = randn(size(X, 2), J-1)
    Î³_initial = randn(1)
    initial_params = vcat(vec(Î²_initial), Î³_initial)

    # Minimize the negative log-likelihood
    result = optimize(params -> log_likelihood(params, X, Z, y, J), initial_params, BFGS())

    # Extract the estimated parameters
    estimated_params = result.minimizer
    Î²_hat = reshape(estimated_params[1:end-1], size(X, 2), J-1)
    Î³_hat = estimated_params[end]

    println("Estimated Î² coefficients: ", Î²_hat)
    println("Estimated Î³ coefficient: ", Î³_hat)
end

# Wrape function for Q3
using CSV, DataFrames, Optim, LinearAlgebra, HTTP
function estimate_nested_logit()
    url = "https://raw.githubusercontent.com/OU-PhD-Econometrics/fall-2024/master/ProblemSets/PS3-gev/nlsw88w.csv"
    df = CSV.read(HTTP.get(url).body, DataFrame)

    # Define the variables
    X = [df.age df.white df.collgrad]
    Z = hcat(df.elnwage1, df.elnwage2, df.elnwage3, df.elnwage4,
             df.elnwage5, df.elnwage6, df.elnwage7, df.elnwage8)
    y = df.occupation

    # Define nests
    WC = [1, 2, 3]  # White collar occupations
    BC = [4, 5, 6, 7]  # Blue collar occupations
    Other = [8]  # Other

    # Log-likelihood function for nested logit
    function log_likelihood_nested(params, X, Z, y, WC, BC, Other)
        Î²_WC = params[1:3]
        Î²_BC = params[4:6]
        Î³ = params[7]
        Î»_WC = params[8]
        Î»_BC = params[9]

        ll = 0.0

        for i in 1:size(X, 1)
            # Calculate sums for the white collar and blue collar nests
            sum_WC = sum(exp((dot(X[i, :], Î²_WC) + Î³ * (Z[i, j] - Z[i, 8])) / Î»_WC) for j in WC)
            sum_BC = sum(exp((dot(X[i, :], Î²_BC) + Î³ * (Z[i, j] - Z[i, 8])) / Î»_BC) for j in BC)

            # Ensure sum_WC and sum_BC are scalars, and then raise to the power of Î»
            denom = sum_WC^Î»_WC + sum_BC^Î»_BC

            if y[i] in WC
                ll += log(exp((dot(X[i, :], Î²_WC) + Î³ * (Z[i, y[i]] - Z[i, 8])) / Î»_WC) / denom)
            elseif y[i] in BC
                ll += log(exp((dot(X[i, :], Î²_BC) + Î³ * (Z[i, y[i]] - Z[i, 8])) / Î»_BC) / denom)
            elseif y[i] in Other
                ll += log(1 / denom)
            end
        end

        return -ll  # Return negative log-likelihood
    end

    # Initial parameter guess (flattened vector)
    initial_params = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0]

    # Optimize the negative log-likelihood
    result = optimize(params -> log_likelihood_nested(params, X, Z, y, WC, BC, Other), initial_params, BFGS())

    # Extract the estimated parameters
    estimated_params = result.minimizer
    Î²_WC_hat = estimated_params[1:3]
    Î²_BC_hat = estimated_params[4:6]
    Î³_hat = estimated_params[7]
    Î»_WC_hat = estimated_params[8]
    Î»_BC_hat = estimated_params[9]

    println("Estimated Î²_WC: ", Î²_WC_hat)
    println("Estimated Î²_BC: ", Î²_BC_hat)
    println("Estimated Î³: ", Î³_hat)
    println("Estimated Î»_WC: ", Î»_WC_hat)
    println("Estimated Î»_BC: ", Î»_BC_hat)
end

# Call the multinomial logit estimation
println("Multinomial Logit Estimation:")
estimate_multinomial_logit()

# Call the nested logit estimation
println("\nNested Logit Estimation:")
estimate_nested_logit()

# Question 5
using Test
using Test

@testset "Multinomial Logit Model Tests" begin
    println("Running tests for Multinomial Logit model...")

    try
        estimate_multinomial_logit()

        J = 8
        Î²_hat = randn(3, J-1)
        Î³_hat = randn()

        @test size(Î²_hat) == (3, J-1) 
        @test Î³_hat isa Float64  

        println("Multinomial Logit model tests passed!")
    catch e
        println("Error during Multinomial Logit tests: ", e)
        @test false 
    end
end

@testset "Nested Logit Model Tests" begin
    println("Running tests for Nested Logit model...")

    try
        estimate_nested_logit()

        Î²_WC_hat = randn(3)
        Î²_BC_hat = randn(3)
        Î³_hat = randn()
        Î»_WC_hat = randn()
        Î»_BC_hat = randn()

        @test length(Î²_WC_hat) == 3 
        @test length(Î²_BC_hat) == 3 
        @test Î³_hat isa Float64  
        @test Î»_WC_hat isa Float64 
        @test Î»_BC_hat isa Float64  

        println("Nested Logit model tests passed!")
    catch e
        println("Error during Nested Logit tests: ", e)
        @test false  
    end
end

